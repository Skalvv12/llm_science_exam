{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q openai","metadata":{"execution":{"iopub.status.busy":"2023-08-07T17:54:26.195141Z","iopub.execute_input":"2023-08-07T17:54:26.196005Z","iopub.status.idle":"2023-08-07T17:54:43.360359Z","shell.execute_reply.started":"2023-08-07T17:54:26.195922Z","shell.execute_reply":"2023-08-07T17:54:43.358403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import libraries\nimport openai, requests, json\nimport pandas as pd\nfrom kaggle_secrets import UserSecretsClient\n\n# Add your openai API key as a secret via Add-Ons -> Secrets\nuser_secrets = UserSecretsClient()\nopenai.api_key = user_secrets.get_secret(\"openai_api_key\")","metadata":{"execution":{"iopub.status.busy":"2023-08-07T17:56:26.747122Z","iopub.execute_input":"2023-08-07T17:56:26.748282Z","iopub.status.idle":"2023-08-07T17:56:26.922418Z","shell.execute_reply.started":"2023-08-07T17:56:26.748243Z","shell.execute_reply":"2023-08-07T17:56:26.921047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the train set\ntrain = pd.read_csv('/kaggle/input/kaggle-llm-science-exam/train.csv')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-07T17:56:58.049598Z","iopub.execute_input":"2023-08-07T17:56:58.050062Z","iopub.status.idle":"2023-08-07T17:56:58.103016Z","shell.execute_reply.started":"2023-08-07T17:56:58.050017Z","shell.execute_reply":"2023-08-07T17:56:58.101869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Pick a row\nrow = train.iloc[0]\n\n# Create our \"prompt\"\nsystem_message = \"\"\"Answer the follwing multiple-choice question by providing your top 3 guesses in order from \nmost to least likely, using the following format: 'A C D' (just the letters separated by spaces).\"\"\"\nuser_message = f\"\"\"Question: {row['prompt']}.Answers: {' '.join([l+': '+row[l] for l in 'ABCDE'])}\n** Remember to answer only with the letters corresponding to your answer. **\"\"\"\n\n# Call the chat completions API with gpt-3.5-turbo model and messages as input\nresponse = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\"role\": \"system\", \"content\": system_message},\n        {\"role\": \"user\", \"content\": user_message}\n    ]\n)\n\n# Extract the assistant message from the response\nassistant_message = response[\"choices\"][0]['message']['content']\n\n# Print the context\nprint(user_message, \"\\n\")\n\n# Print the assistant message, hopefully containint our answer\nprint('Answer:', assistant_message)","metadata":{"execution":{"iopub.status.busy":"2023-08-07T18:12:36.352447Z","iopub.execute_input":"2023-08-07T18:12:36.352918Z","iopub.status.idle":"2023-08-07T18:12:36.991208Z","shell.execute_reply.started":"2023-08-07T18:12:36.352883Z","shell.execute_reply":"2023-08-07T18:12:36.989802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Run this over 100 rows for quick estimate\nscore = 0\nfor idx, row in train[:100].iterrows():\n    \n    # Create our \"prompt\"\n    system_message = \"\"\"Answer the follwing multiple-choice question by providing your top 3 guesses in order from \n    most to least likely, using the following format: 'A C D' (just the letters separated by spaces).\"\"\"\n    user_message = f\"\"\"Question: {row['prompt']}.Answers: {' '.join([l+': '+row[l] for l in 'ABCDE'])}\n    ** Remember to answer only with the letters corresponding to your answer. **\"\"\"\n\n    # Call the chat completions API with gpt-3.5-turbo model and messages as input\n    response = openai.ChatCompletion.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[\n            {\"role\": \"system\", \"content\": system_message},\n            {\"role\": \"user\", \"content\": user_message}\n        ]\n    )\n\n    # Extract the assistant message from the response\n    assistant_message = response[\"choices\"][0]['message']['content']\n\n    # Score\n    answers = assistant_message.split(' ')[:3]\n    correct_answer = row['answer']\n    for i, guess in enumerate(answers):\n        if guess == correct_answer:\n            score += 1/(i+1) # 1 for first guess, 1/2 for second and 1/3 for third\n            \nprint(\"Average Score:\", score/100)","metadata":{"execution":{"iopub.status.busy":"2023-08-07T18:18:20.973374Z","iopub.execute_input":"2023-08-07T18:18:20.973904Z","iopub.status.idle":"2023-08-07T18:19:02.976274Z","shell.execute_reply.started":"2023-08-07T18:18:20.973871Z","shell.execute_reply":"2023-08-07T18:19:02.974936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Structured Output with Function Calling","metadata":{}},{"cell_type":"code","source":"def generate_answer(row):\n    # System prompt\n    system_message = f\"\"\"Answer the follwing multiple-choice question by providing your top 3 guesses along with your reasoning.\"\"\"\n\n    # Set the user message with the specific context\n    user_message = user_message = f\"\"\"Question: {row['prompt']}. Answers: {' '.join([l+': '+row[l] for l in 'ABCDE'])}\"\"\"\n\n    # Define the function(s) the model will be able to use (in this case, only one)\n    functions = [\n        {\n            \"name\": \"answer_question\",\n            \"description\": \"Answers the provided question\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"reasoning\": {\n                    \"type\": \"string\",\n                    \"description\": \"Reasining for what the answer could be. Keep it short.\"\n                    },\n                    \"answers\": {\n                    \"type\": \"array\",\n                    \"items\": {\n                        \"type\": \"string\",\n                        \"enum\": [\"A\", \"B\", \"C\", \"D\", \"E\"],\n                    },\n                    \"description\": \"Your top 3 guesses, from most to least likely. e.g. ['A', 'D', 'C']\"\n                    }\n                },\n                \"required\": [\"reasoning\", \"answers\"],\n            },\n        }\n    ]\n\n    # Call the chat completions API with the function calling parameters\n    response = openai.ChatCompletion.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[\n            {\"role\": \"system\", \"content\": system_message},\n            {\"role\": \"user\", \"content\": user_message}\n        ],\n        functions=functions, # Add the function\n        function_call={\"name\": \"answer_question\"} # Force the function call\n    )\n\n    # Extract the function call arguments\n    args = json.loads(response['choices'][0]['message']['function_call']['arguments'])\n\n    return args","metadata":{"execution":{"iopub.status.busy":"2023-08-07T18:23:46.127662Z","iopub.execute_input":"2023-08-07T18:23:46.128647Z","iopub.status.idle":"2023-08-07T18:23:46.140773Z","shell.execute_reply.started":"2023-08-07T18:23:46.128590Z","shell.execute_reply":"2023-08-07T18:23:46.139490Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Example response - note we get a nice dictionary with just what we wanted!\ngenerate_answer(train.iloc[0])","metadata":{"execution":{"iopub.status.busy":"2023-08-07T18:23:59.902738Z","iopub.execute_input":"2023-08-07T18:23:59.903270Z","iopub.status.idle":"2023-08-07T18:24:02.480083Z","shell.execute_reply.started":"2023-08-07T18:23:59.903232Z","shell.execute_reply":"2023-08-07T18:24:02.478651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Run this over 100 rows to compare with the previous approach.\nscore = 0\nfor idx, row in train[:100].iterrows():\n    a = generate_answer(row)\n    answers = a['answers'][:3] # No need for string splitting :)\n    correct_answer = row['answer']\n    for i, guess in enumerate(answers):\n        if guess == correct_answer:\n            score += 1/(i+1) # 1 for first guess, 1/2 for second and 1/3 for third\n            \nprint(\"Average Score:\", score/100)","metadata":{"execution":{"iopub.status.busy":"2023-08-07T18:25:11.916872Z","iopub.execute_input":"2023-08-07T18:25:11.917373Z","iopub.status.idle":"2023-08-07T18:28:56.862372Z","shell.execute_reply.started":"2023-08-07T18:25:11.917338Z","shell.execute_reply":"2023-08-07T18:28:56.861036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Challenge: How good ca you get? Try your prompt engineering skills!\nTip: Try things out on a few questions first, and print everything out to check it's working as you expect before running something 200 times :)","metadata":{}}]}